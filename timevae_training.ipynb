{"cells":[{"cell_type":"markdown","metadata":{"id":"fjLzPOrAZZBu"},"source":["# Bachelor. Conveyor belt state classification using deep neural networks and data augmentation methods.\n","\n","Vilnius University \\\\\n","Software Engineering \\\\\n","Student Armantas Pikšrys"]},{"cell_type":"markdown","metadata":{"id":"DiOgyPTmZpXn"},"source":["## Mount data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W4IdRJJj7KKk","outputId":"9f455c5d-c5a8-43d9-907e-4d68233fb6c1","trusted":true},"outputs":[],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N8fbuSfT7vKp","outputId":"6dde0a90-ce46-4497-f0ed-040d9b54e5c9","trusted":true},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mPXcCmw45EC1","outputId":"f6c14c01-b6ab-4468-cb88-1b22aa2d9383","trusted":true},"outputs":[],"source":["gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n","print(gpu_devices)\n","if gpu_devices:\n","    print('Using GPU')\n","    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n","else:\n","    print('Using CPU')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ke8Wwhv7u1iM","trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout\n","from keras import backend as K\n","from keras.models import Sequential\n","from keras.layers import TimeDistributed, Conv1D, BatchNormalization, AveragePooling1D, Dropout, Flatten\n","from keras.layers import LSTM, Dense\n","from keras import layers\n","from keras.optimizers import Adam\n","import tensorflow as tf\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mK34hUSQnejb","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","import tensorflow as tf\n","from pathlib import Path\n","from tqdm import tqdm\n","\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import GRU, Dense, RNN, GRUCell, Input\n","from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import TensorBoard\n","from tensorflow.keras.utils import plot_model\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from __future__ import print_function\n","import numpy as np\n","import tensorflow as tf\n","import six\n","from timeit import default_timer as timer"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Set the window size\n","window_size = 320\n","\n","# Directory where your files are located\n","data_dir = \"/kaggle/input/weight-data-kilos\"  # Replace with the actual directory path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fqMJPTMPfTMv","trusted":true},"outputs":[],"source":["# Initialize empty lists for signals and labels\n","signals = []\n","labels = []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtgWadDOPKHH","outputId":"6debb0d4-5ecb-41a8-a354-a8df1f3b2a83","trusted":true},"outputs":[],"source":["# Iterate over files in the directory\n","for filename in os.listdir(data_dir):\n","    if filename.endswith(\".csv\"):\n","        file_path = os.path.join(data_dir, filename)\n","        if float(filename.split(\"_\")[0]) == 5:\n","\n","            # Load CSV data\n","            data = pd.read_csv(file_path)\n","\n","            # Create signals using a sliding window\n","            num_rows = len(data)\n","            step_size = 1\n","\n","            for i in range(0, num_rows - window_size + 1, step_size):\n","                window_data = data[i:i + window_size]\n","                signals.append(window_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C5UZ-MTMfhYL","trusted":true},"outputs":[],"source":["# Convert the lists to NumPy arrays\n","signals_array = np.array(signals, dtype=np.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gRvRWVCckdZ7","trusted":true},"outputs":[],"source":["signal_max = signals_array.max()\n","signal_min = signals_array.min()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tiIz7ol2fr6K","trusted":true},"outputs":[],"source":["data = (signals_array - signal_min) / (signal_max - signal_min)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oRPPmwjsfw6d","outputId":"3b44a908-5d1b-426b-8385-228962ea2d22","trusted":true},"outputs":[],"source":["data_max = data.max()\n","data_min = data.min()\n","\n","data_max, data_min"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["signals_array.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!git clone https://github.com/abudesai/timeVAE.git"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cd timeVAE"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os, warnings\n","# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n","# warnings.filterwarnings('ignore') \n","\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # disabling gpu usage because my cuda is corrupted, needs to be fixed. \n","\n","import sys\n","import numpy as np , pandas as pd\n","import time\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from vae_dense_model import VariationalAutoencoderDense as VAE_Dense\n","from vae_conv_model import VariationalAutoencoderConv as VAE_Conv\n","from vae_conv_I_model import VariationalAutoencoderConvInterpretable as TimeVAE\n","import utils"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["start = time.time()\n","\n","vae_type = 'timeVAE' \n","\n","full_train_data = data\n","N, T, D = full_train_data.shape   \n","print('data shape:', N, T, D) "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# further split the training data into train and validation set - same thing done in forecasting task\n","perc_of_train_used = 20     # 5, 10, 20, 100    \n","valid_perc = 0.1\n","N_train = int(N * (1 - valid_perc))\n","N_valid = N - N_train\n","\n","# Shuffle data\n","np.random.shuffle(full_train_data)\n","\n","train_data = full_train_data[:N_train]\n","valid_data = full_train_data[N_train:]   \n","print(\"train/valid shapes: \", train_data.shape, valid_data.shape)    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["scaled_train_data = train_data\n","\n","scaled_valid_data = valid_data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","time_axis = np.arange(window_size)\n","# Plot all channels in a single plot\n","plt.figure(figsize=(12, 6))\n","\n","plt.plot(time_axis, scaled_train_data[2][:, 0], label='Channel 1', color='blue')\n","plt.plot(time_axis, scaled_train_data[2][:, 1], label='Channel 2', color='green')\n","plt.plot(time_axis, scaled_train_data[2][:, 2], label='Channel 3', color='red')\n","\n","plt.title('Signal Channels')\n","plt.xlabel('Time')\n","plt.ylabel('Amplitude')\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# ----------------------------------------------------------------------------------\n","# instantiate the model     \n","\n","latent_dim = 20\n","\n","if vae_type == 'vae_dense': \n","    vae = VAE_Dense( seq_len=T,  feat_dim = D, latent_dim = latent_dim, hidden_layer_sizes=[200,100], )\n","elif vae_type == 'vae_conv':\n","    vae = VAE_Conv( seq_len=T,  feat_dim = D, latent_dim = latent_dim, hidden_layer_sizes=[100, 200] )\n","elif vae_type == 'timeVAE':\n","    vae = TimeVAE( seq_len=T,  feat_dim = D, latent_dim = latent_dim, hidden_layer_sizes=[50, 100, 200],        #[80, 200, 250] [50, 100, 200]\n","            reconstruction_wt = 15.0,\n","            # ---------------------\n","            # disable following three arguments to use the model as TimeVAE_Base. Enabling will convert to Interpretable version.\n","            # Also set use_residual_conn= False if you want to only have interpretable components, and no residual (non-interpretable) component. \n","\n","#             trend_poly=2, \n","#             custom_seas = [ (6,1), (7, 1), (8,1), (9,1)] ,     # list of tuples of (num_of_seasons, len_per_season)\n","#             use_scaler = True,\n","\n","            #---------------------------\n","            use_residual_conn = True\n","        )   \n","else:  raise Exception('wut')\n","\n","\n","vae.compile(optimizer=Adam())\n","# vae.summary() ; sys.exit()\n","\n","early_stop_loss = 'loss'\n","early_stop_callback = EarlyStopping(monitor=early_stop_loss, min_delta = 1e-1, patience=10) \n","reduceLR = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5)\n","\n","vae.fit(\n","    scaled_train_data, \n","    batch_size = 32,\n","    epochs=200,\n","    shuffle = True,\n","    callbacks=[early_stop_callback, reduceLR],\n","    verbose = 1\n",")\n","\n","# ----------------------------------------------------------------------------------    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # ----------------------------------------------------------------------------------    \n","# # save model \n","# model_dir = './model/'\n","# file_pref = f'vae_{vae_type}_sine_perc_{perc_of_train_used}_iter_{0}_'\n","# vae.save(model_dir, file_pref)\n","\n","# # ----------------------------------------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def draw_orig_and_post_pred_sample_custom(orig, reconst, n):\n","\n","    fig, axs = plt.subplots(n, 2, figsize=(10,6))\n","    i = 1\n","    for _ in range(n):\n","        rnd_idx = np.random.choice(len(orig))\n","        o = orig[rnd_idx]\n","        r = reconst[rnd_idx]\n","\n","        plt.subplot(n, 2, i)\n","        plt.imshow(o, \n","            # cmap='gray', \n","            aspect='auto')\n","        # plt.title(\"Original\")\n","        i += 1\n","\n","        plt.subplot(n, 2, i)\n","        plt.imshow(r, \n","            # cmap='gray', \n","            aspect='auto')\n","        # plt.title(\"Sampled\")\n","        i += 1\n","\n","    fig.suptitle(\"Originalūs ir Rekonstruoti duomenys\")\n","    fig.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# ----------------------------------------------------------------------------------\n","# visually check reconstruction \n","X = scaled_train_data\n","\n","x_decoded = vae.predict(scaled_train_data)\n","print('x_decoded.shape', x_decoded.shape)\n","\n","### compare original and posterior predictive (reconstructed) samples\n","draw_orig_and_post_pred_sample_custom(X, x_decoded, n=5)\n","\n","\n","# # Plot the prior generated samples over different areas of the latent space\n","if latent_dim == 2: utils.plot_latent_space_timeseries(vae, n=8, figsize = (20, 10))\n","\n","# # ----------------------------------------------------------------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","time_axis = np.arange(window_size)\n","# Plot all channels in a single plot\n","plt.figure(figsize=(12, 6))\n","\n","plt.plot(time_axis, scaled_train_data[0][:, 0], label='Kanalas 1', color='blue')\n","plt.plot(time_axis, scaled_train_data[0][:, 1], label='Kanalas 2', color='green')\n","plt.plot(time_axis, scaled_train_data[0][:, 2], label='Kanalas 3', color='red')\n","\n","plt.title('Originalas')\n","plt.xlabel('Laikas')\n","plt.ylabel('Amplitudė')\n","plt.legend()\n","\n","plt.show()\n","\n","time_axis = np.arange(window_size)\n","# Plot all channels in a single plot\n","plt.figure(figsize=(12, 6))\n","\n","plt.plot(time_axis, x_decoded[0][:, 0], label='Kanalas 1', color='blue')\n","plt.plot(time_axis, x_decoded[0][:, 1], label='Kanalas 2', color='green')\n","plt.plot(time_axis, x_decoded[0][:, 2], label='Kanalas 3', color='red')\n","\n","plt.title('Rekonstrukcija')\n","plt.xlabel('Laikas')\n","plt.ylabel('Amplitudė')\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# draw random prior samples\n","num_samples = N_train\n","# print(\"num_samples: \", num_samples)\n","\n","samples = vae.get_prior_samples(num_samples=3)\n","\n","fig, axs = plt.subplots(3, 1, figsize=(6,8))\n","for i in range(3):\n","    s = samples[i]\n","    axs[i].plot(s)    \n","\n","fig.suptitle(\"Generated Samples (Scaled)\")\n","fig.tight_layout()\n","plt.show()\n","\n","fig, axs = plt.subplots(3, 1, figsize=(6,8))\n","i = 0\n","for i in range(3):\n","    rnd_idx = np.random.choice(len(samples))\n","    s = scaled_train_data[rnd_idx]\n","    axs[i].plot(s)    \n","    i += 1 \n","\n","fig.suptitle(\"Real Samples (Scaled)\")\n","fig.tight_layout()\n","plt.show()\n","\n","# inverse-transform scaling \n","# samples = scaler.inverse_transform(samples)\n","# print('shape of gen samples: ', samples.shape) "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# draw random prior samples\n","num_samples = N_train\n","# print(\"num_samples: \", num_samples)\n","\n","#metrics_samples = vae.get_prior_samples(num_samples=N_train)\n","metrics_samples = vae.get_prior_samples(num_samples=40000)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["scaled_train_data.shape, metrics_samples.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","\n","# Calculate Mean Squared Error (MSE) for each dimension\n","mse_per_dimension = np.mean(np.mean((scaled_train_data - metrics_samples)**2, axis=0))\n","print(f'Mean Squared Error per Dimension: {mse_per_dimension}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["samples = metrics_samples * (signal_max - signal_min) + signal_min"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(3, 1, figsize=(6,8))\n","for i in range(3):\n","    s = samples[i]\n","    axs[i].plot(s)    \n","\n","fig.suptitle(\"Generated Samples (Scaled)\")\n","fig.tight_layout()\n","plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7490401,"datasetId":4241531,"sourceId":7399320,"sourceType":"datasetVersion"},{"sourceId":158140953,"sourceType":"kernelVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
